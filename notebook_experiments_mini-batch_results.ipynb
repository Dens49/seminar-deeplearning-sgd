{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if IN_COLAB:\n",
    "    print(\"running in google colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.chdir(\"/content/drive/My Drive/seminar_dl_workspace\")\n",
    "    print(\"switched workspace:\", os.getcwd())\n",
    "    \n",
    "from create_visualizations import get_filenames_in_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "def show_svg(filename):\n",
    "    display(SVG(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boilerplate done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 10000]\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "\n",
    "def transform_experiment_name_to_heat_map_idx(name):\n",
    "    matches = re.search(r\"(\\d+)_([0-9]*\\.?[0-9]+)\\.csv$\", name)\n",
    "    batch_size = int(matches.group(1))\n",
    "    lr = float(matches.group(2))\n",
    "    return batch_sizes.index(batch_size), learning_rates.index(lr)\n",
    "\n",
    "def get_latest_experiment_df(csv_path):\n",
    "    experiment_stats = pd.read_csv(csv_path)\n",
    "    experiment_stats_grouped = experiment_stats.groupby(\"experiment_id\")\n",
    "    latest_training_session = experiment_stats_grouped.get_group(experiment_stats.experiment_id.max())\n",
    "    if len(experiment_stats) < 20:\n",
    "        print(f\"WARNING: file {csv_path} has only {len(experiment_stats)} epochs but should have 20\")\n",
    "    elif len(experiment_stats) > 20 and len(experiment_stats) % 20 == 0:\n",
    "        print(f\"INFO: file {csv_path} has {experiment_stats_grouped.ngroups} training sessions. Using latest training session with {len(latest_training_session)} epochs and experiment_id {latest_training_session.iloc[0]['experiment_id']}\")\n",
    "    return latest_training_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map_dimensions = (len(batch_sizes), len(learning_rates))\n",
    "heat_map_test_acc = np.zeros(heat_map_dimensions)\n",
    "heat_map_train_acc = np.zeros(heat_map_dimensions)\n",
    "heat_map_test_avg_loss = np.full(heat_map_dimensions, 2.5)\n",
    "heat_map_train_avg_loss = np.full(heat_map_dimensions, 2.5)\n",
    "\n",
    "experiments_stats_filenames = get_filenames_in_dir(\"experiments_stats\", lambda x: \"SGD_with_variable_batch_size_\" in x)\n",
    "print(f\"found {len(experiments_stats_filenames)} experiments for SGD_with_variable_batch_size\")\n",
    "for filename in experiments_stats_filenames:\n",
    "    i,k = transform_experiment_name_to_heat_map_idx(filename)\n",
    "    df = get_latest_experiment_df(os.path.join(\"experiments_stats\" , filename))\n",
    "    heat_map_test_acc[i,k] = df[\"test_acc\"].max()\n",
    "    heat_map_train_acc[i,k] = df[\"train_acc\"].max()\n",
    "    heat_map_test_avg_loss[i,k] = df[\"test_avg_loss\"].min()\n",
    "    heat_map_train_avg_loss[i,k] = df[\"train_avg_loss\"].min()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(28, 15))\n",
    "fig.suptitle(\"SGD batch size vs. learning rate after 20 epochs\")\n",
    "xticklabels = learning_rates.copy()\n",
    "xticklabels[0] = r\"$10^{-4}$\"\n",
    "xticklabels[1] = r\"$10^{-3}$\"\n",
    "xticklabels[2] = r\"$10^{-2}$\"\n",
    "\n",
    "def draw_subplot_batch_size_lr_heatmap(ax, heat_map, title, mark_max=False, mark_min=False):\n",
    "    im = ax.imshow(heat_map, cmap=\"rainbow\", aspect=\"auto\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(len(learning_rates)))\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_xlabel(\"learning rate\")\n",
    "    ax.set_yticks(range(len(batch_sizes)))\n",
    "    ax.set_yticklabels(batch_sizes)\n",
    "    ax.set_ylabel(\"batch size\")\n",
    "    plt.colorbar(im, ax=ax, fraction=0.025, pad=0.01)\n",
    "\n",
    "    # annotate heat map and mark max/min values\n",
    "    max_i, max_k = np.where(heat_map == np.amax(heat_map))\n",
    "    max_i = max_i[0]\n",
    "    max_k = max_k[0]\n",
    "    min_i, min_k = np.where(heat_map == np.min(heat_map))\n",
    "    min_i = min_i[0]\n",
    "    min_k = min_k[0]\n",
    "    for i in range(len(batch_sizes)):\n",
    "        for k in range(len(learning_rates)):\n",
    "            value = heat_map[i, k]\n",
    "            fw = \"normal\"\n",
    "            color = \"black\"\n",
    "            if mark_max and i == max_i and k == max_k:\n",
    "                fw = \"bold\"\n",
    "                color = \"white\"\n",
    "            elif mark_min and i == min_i and k == min_k:\n",
    "                fw = \"bold\"\n",
    "                color = \"white\"\n",
    "            ax.text(k, i, round(value, 2), ha=\"center\", va=\"center\", fontweight=fw, color=color, fontsize=12)\n",
    "        \n",
    "    # fix cutting off top and bottom row bug: https://github.com/matplotlib/matplotlib/issues/14751#issuecomment-511017375\n",
    "    ax.set_ylim(len(batch_sizes) - 0.5, -0.5)\n",
    "    return (max_i, max_k), (min_i, min_k)\n",
    "\n",
    "max_train_acc_idx, _ = draw_subplot_batch_size_lr_heatmap(axs[0, 0], heat_map_train_acc, \"train accuracy\", mark_max=True)\n",
    "max_test_acc_idx, _ = draw_subplot_batch_size_lr_heatmap(axs[0, 1], heat_map_test_acc, \"test accuracy\", mark_max=True)\n",
    "_, min_train_avg_loss_idx = draw_subplot_batch_size_lr_heatmap(axs[1, 0], heat_map_train_avg_loss, \"train avg loss\", mark_min=True)\n",
    "_, min_test_avg_loss_idx = draw_subplot_batch_size_lr_heatmap(axs[1, 1], heat_map_test_avg_loss, \"test avg loss\", mark_min=True)\n",
    "print(f\"max train accuracy: batch_size={batch_sizes[max_train_acc_idx[0]]} lr={learning_rates[max_train_acc_idx[1]]} --> {heat_map_train_acc[max_train_acc_idx]}\")\n",
    "print(f\"max test accuracy: batch_size={batch_sizes[max_test_acc_idx[0]]} lr={learning_rates[max_test_acc_idx[1]]} --> {heat_map_test_acc[max_test_acc_idx]}\")\n",
    "print(f\"min train avg loss: batch_size={batch_sizes[min_train_avg_loss_idx[0]]} lr={learning_rates[min_train_avg_loss_idx[1]]} --> {heat_map_train_avg_loss[min_train_avg_loss_idx]}\")\n",
    "print(f\"min test avg loss: batch_size={batch_sizes[min_test_avg_loss_idx[0]]} lr={learning_rates[min_test_avg_loss_idx[1]]} --> {heat_map_test_avg_loss[min_test_avg_loss_idx]}\")\n",
    "plt.savefig(\"visualizations/sgd_batch_size_vs_learning_rate_heat_maps.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_subplot_batch_size_lr_lines(ax, data, title, ylabel=\"\", ylim=None, legend_is_outside=False, make_line_idx_fat=None):\n",
    "    line_objects = ax.plot(data)\n",
    "    if make_line_idx_fat is not None:\n",
    "        line_objects[make_line_idx_fat].set_linewidth(3.0)\n",
    "        line_objects[make_line_idx_fat].zorder = 99\n",
    "    if legend_is_outside:\n",
    "        ax.legend(iter(line_objects), batch_sizes, loc=\"center left\", bbox_to_anchor=(0.96, 0.5))\n",
    "    else:\n",
    "        ax.legend(iter(line_objects), batch_sizes)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(range(len(learning_rates)))\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_xlabel(\"learning rate\")\n",
    "    ax.grid()\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot avg losses and accuracies vs learning rate as lines for different batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(28, 15), gridspec_kw=dict(hspace=0.35))\n",
    "fig.suptitle(\"SGD batch size vs learning rate after 20 epochs\")\n",
    "\n",
    "draw_subplot_batch_size_lr_lines(axs[0, 0], heat_map_train_acc.T, \"Train Accuracy vs learning rate for different batch sizes\", ylabel=\"accuracy\", legend_is_outside=True)\n",
    "draw_subplot_batch_size_lr_lines(axs[0, 1], heat_map_test_acc.T, \"Test Accuracy vs learning rate for different batch sizes\", ylabel=\"accuracy\", legend_is_outside=True)\n",
    "draw_subplot_batch_size_lr_lines(axs[1, 0], heat_map_train_avg_loss.T, \"Train avg loss vs learning rate for different batch sizes\", ylabel=\"loss\", legend_is_outside=True)\n",
    "draw_subplot_batch_size_lr_lines(axs[1, 1], heat_map_test_avg_loss.T, \"Test avg loss vs learning rate for different batch sizes\", ylabel=\"loss\", legend_is_outside=True)\n",
    "plt.savefig(\"visualizations/sgd_batch_size_vs_learning_rate_lines_big.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(28, 15), gridspec_kw=dict(hspace=0.35, wspace=0.2))\n",
    "fig.suptitle(\"SGD batch size vs learning rate after 20 epochs\")\n",
    "\n",
    "draw_subplot_batch_size_lr_lines(axs[0, 0], heat_map_train_acc.T, \"Train Accuracy vs learning rate for different batch sizes\", ylabel=\"accuracy\", ylim=(0.9, 0.975), legend_is_outside=True, make_line_idx_fat=2)\n",
    "draw_subplot_batch_size_lr_lines(axs[0, 1], heat_map_test_acc.T, \"Test Accuracy vs learning rate for different batch sizes\", ylabel=\"accuracy\", ylim=(0.7, 0.84), legend_is_outside=True, make_line_idx_fat=2)\n",
    "draw_subplot_batch_size_lr_lines(axs[1, 0], heat_map_train_avg_loss.T, \"Train avg loss vs learning rate for different batch sizes\", ylabel=\"loss\", ylim=(0.08, 0.25), legend_is_outside=True, make_line_idx_fat=2)\n",
    "draw_subplot_batch_size_lr_lines(axs[1, 1], heat_map_test_avg_loss.T, \"Test avg loss vs learning rate for different batch sizes\", ylabel=\"loss\", ylim=(0.5, 1.0), legend_is_outside=True, make_line_idx_fat=2)\n",
    "plt.savefig(\"visualizations/sgd_batch_size_vs_learning_rate_lines_zoomed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
