{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if IN_COLAB:\n",
    "    print(\"running in google colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.chdir(\"/content/drive/My Drive/seminar_dl_workspace\")\n",
    "    print(\"switched workspace:\", os.getcwd())\n",
    "    \n",
    "from create_visualizations import get_filenames_in_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "def show_svg(filename):\n",
    "    display(SVG(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boilerplate done..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: in these first experiment results a 3-dimensional grid search was done over batch_size, lr and momentum to find a suitable combination for further experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [16, 128, 256]\n",
    "learning_rates = [0.01, 0.04, 0.45]\n",
    "momentums = [0.875, 0.9, 0.925]\n",
    "\n",
    "def get_batch_size_lr_and_momentum_from_experiment_name(name):\n",
    "    matches = re.search(r\"([0-9]*\\.?[0-9]+)_(\\d+)_([0-9]*\\.?[0-9]+)\\.csv$\", name)\n",
    "    momentum = float(matches.group(1))\n",
    "    batch_size = int(matches.group(2))\n",
    "    lr = float(matches.group(3))\n",
    "    return batch_size, lr, momentum\n",
    "\n",
    "def get_latest_experiment_df(csv_path):\n",
    "    experiment_stats = pd.read_csv(csv_path)\n",
    "    experiment_stats_grouped = experiment_stats.groupby(\"experiment_id\")\n",
    "    latest_training_session = experiment_stats_grouped.get_group(experiment_stats.experiment_id.max())\n",
    "    if len(experiment_stats) < 20:\n",
    "        print(f\"WARNING: file {csv_path} has only {len(experiment_stats)} epochs but should have 20\")\n",
    "    elif len(experiment_stats) > 20 and len(experiment_stats) % 20 == 0:\n",
    "        print(f\"INFO: file {csv_path} has {experiment_stats_grouped.ngroups} training sessions. Using latest training session with {len(latest_training_session)} epochs and experiment_id {latest_training_session.iloc[0]['experiment_id']}\")\n",
    "    return latest_training_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find best batch size and learning rate for these first experiments in order to do a more fine grained experiment run with more momentums but with fixed lr and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (len(batch_sizes), len(learning_rates), len(momentums))\n",
    "results_test_acc = np.zeros(dims)\n",
    "results_train_acc = np.zeros(dims)\n",
    "results_test_avg_loss = np.zeros(dims)\n",
    "results_train_avg_loss = np.zeros(dims)\n",
    "\n",
    "experiments_stats_filenames = get_filenames_in_dir(\"experiments_stats\", lambda x: \"SGD_with_momentum_\" in x)\n",
    "print(f\"found {len(experiments_stats_filenames)} experiments for SGD_with_momentum_\")\n",
    "for filename in experiments_stats_filenames:\n",
    "    batch_size, lr, momentum = get_batch_size_lr_and_momentum_from_experiment_name(filename)\n",
    "    if lr not in learning_rates or momentum not in momentums:\n",
    "        continue\n",
    "    i = batch_sizes.index(batch_size)\n",
    "    j = learning_rates.index(lr)\n",
    "    k = momentums.index(momentum)\n",
    "    df = get_latest_experiment_df(os.path.join(\"experiments_stats\" , filename))\n",
    "    results_test_acc[i, j, k] = df[\"test_acc\"].max()\n",
    "    results_train_acc[i, j, k] = df[\"train_acc\"].max()\n",
    "    results_test_avg_loss[i, j, k] = df[\"test_avg_loss\"].min()\n",
    "    results_train_avg_loss[i, j, k] = df[\"train_avg_loss\"].min()\n",
    "\n",
    "max_train_acc = results_train_acc.max()\n",
    "max_test_acc = results_test_acc.max()\n",
    "min_train_loss = results_train_avg_loss.min()\n",
    "min_test_loss = results_test_avg_loss.min()\n",
    "print(f\"max train accuracy: batch_size={batch_sizes[np.where(results_train_acc == max_train_acc)[0][0]]} lr={learning_rates[np.where(results_train_acc == max_train_acc)[1][0]]} momentum={momentums[np.where(results_train_acc == max_train_acc)[2][0]]} --> {max_train_acc}\")\n",
    "print(f\"max test accuracy: batch_size={batch_sizes[np.where(results_test_acc == max_test_acc)[0][0]]} lr={learning_rates[np.where(results_test_acc == max_test_acc)[1][0]]} momentum={momentums[np.where(results_test_acc == max_test_acc)[2][0]]} --> {max_test_acc}\")\n",
    "print(f\"min train avg loss: batch_size={batch_sizes[np.where(results_train_avg_loss == min_train_loss)[0][0]]} --> {min_train_loss}\")\n",
    "print(f\"min test avg loss: batch_size={batch_sizes[np.where(results_test_avg_loss == min_test_loss)[0][0]]} --> {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> choose batch_size=16 and lr=0.01 and 0.04 for further experiments but also lr=0.35 because that learning rate at batch size 16 had the best test accuracy in the previous regular SGD experiments\n",
    "\n",
    "2: check results for the more fine grained experiments: see notebook_experiments_momentum_results.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
