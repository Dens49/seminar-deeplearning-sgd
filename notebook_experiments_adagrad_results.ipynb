{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if IN_COLAB:\n",
    "    print(\"running in google colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.chdir(\"/content/drive/My Drive/seminar_dl_workspace\")\n",
    "    print(\"switched workspace:\", os.getcwd())\n",
    "    \n",
    "from create_visualizations import get_filenames_in_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "def show_svg(filename):\n",
    "    display(SVG(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boilerplate done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "def get_batch_size_from_experiment_name(name):\n",
    "    matches = re.search(r\"([0-9]*)\\.csv$\", name)\n",
    "    batch_size = int(matches.group(1))\n",
    "    return batch_size\n",
    "\n",
    "def get_latest_experiment_df(csv_path):\n",
    "    experiment_stats = pd.read_csv(csv_path)\n",
    "    experiment_stats_grouped = experiment_stats.groupby(\"experiment_id\")\n",
    "    latest_training_session = experiment_stats_grouped.get_group(experiment_stats.experiment_id.max())\n",
    "    if len(experiment_stats) < 20:\n",
    "        print(f\"WARNING: file {csv_path} has only {len(experiment_stats)} epochs but should have 20\")\n",
    "    elif len(experiment_stats) > 20 and len(experiment_stats) % 20 == 0:\n",
    "        print(f\"INFO: file {csv_path} has {experiment_stats_grouped.ngroups} training sessions. Using latest training session with {len(latest_training_session)} epochs and experiment_id {latest_training_session.iloc[0]['experiment_id']}\")\n",
    "    return latest_training_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = len(batch_sizes)\n",
    "results_test_acc = np.zeros(amount)\n",
    "results_train_acc = np.zeros(amount)\n",
    "results_test_avg_loss = np.zeros(amount)\n",
    "results_train_avg_loss = np.zeros(amount)\n",
    "\n",
    "experiments_stats_filenames = get_filenames_in_dir(\"experiments_stats\", lambda x: \"Adagrad_batch_size_\" in x)\n",
    "print(f\"found {len(experiments_stats_filenames)} experiments for Adagrad_batch_size\")\n",
    "for filename in experiments_stats_filenames:\n",
    "    batch_size = get_batch_size_from_experiment_name(filename)\n",
    "    i = batch_sizes.index(batch_size)\n",
    "    df = get_latest_experiment_df(os.path.join(\"experiments_stats\" , filename))\n",
    "    results_test_acc[i] = df[\"test_acc\"].max()\n",
    "    results_train_acc[i] = df[\"train_acc\"].max()\n",
    "    results_test_avg_loss[i] = df[\"test_avg_loss\"].min()\n",
    "    results_train_avg_loss[i] = df[\"train_avg_loss\"].min()\n",
    "\n",
    "max_train_acc = results_train_acc.max()\n",
    "max_test_acc = results_test_acc.max()\n",
    "min_train_loss = results_train_avg_loss.min()\n",
    "min_test_loss = results_test_avg_loss.min()\n",
    "print(f\"max train accuracy: batch_size={batch_sizes[np.where(results_train_acc == max_train_acc)[0][0]]} --> {max_train_acc}\")\n",
    "print(f\"max test accuracy: batch_size={batch_sizes[np.where(results_test_acc == max_test_acc)[0][0]]} --> {max_test_acc}\")\n",
    "print(f\"min train avg loss: batch_size={batch_sizes[np.where(results_train_avg_loss == min_train_loss)[0][0]]} --> {min_train_loss}\")\n",
    "print(f\"min test avg loss: batch_size={batch_sizes[np.where(results_test_avg_loss == min_test_loss)[0][0]]} --> {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_subplot_bar(ax, data, title, ylabel=\"\", ylim=None):\n",
    "    ax.bar(list(map(lambda x: str(x), batch_sizes)), data)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(\"batch size\")\n",
    "    bar_label_y_padding = 0\n",
    "    bar_label_y_pos = 0\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "        bar_label_y_padding = (ylim[1] - ylim[0]) * 0.05\n",
    "        bar_label_y_pos = ylim[0]\n",
    "    for i, v in enumerate(data):\n",
    "        ax.text(i - 0.38, bar_label_y_pos + bar_label_y_padding, round(v, 3), fontsize=18, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot avg losses and accuracies for different batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(28, 15), gridspec_kw=dict(hspace=0.35))\n",
    "fig.suptitle(\"Adagrad for different batch sizes after 20 epochs\")\n",
    "\n",
    "draw_subplot_bar(axs[0, 0], results_train_acc, \"Train Accuracy for different batch sizes\", ylabel=\"accuracy\", ylim=(0.7, 1.0))\n",
    "draw_subplot_bar(axs[0, 1], results_test_acc, \"Test Accuracy for different batch sizes\", ylabel=\"accuracy\", ylim=(0.5, 0.8))\n",
    "draw_subplot_bar(axs[1, 0], results_train_avg_loss, \"Train avg loss for different batch sizes\", ylabel=\"loss\", ylim=(0.0, 0.7))\n",
    "draw_subplot_bar(axs[1, 1], results_test_avg_loss, \"Test avg loss for different batch sizes\", ylabel=\"loss\", ylim=(0.0, 0.9))\n",
    "\n",
    "plt.savefig(\"visualizations/adagrad_batch_sizes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
