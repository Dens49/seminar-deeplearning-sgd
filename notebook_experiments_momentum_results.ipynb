{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if IN_COLAB:\n",
    "    print(\"running in google colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.chdir(\"/content/drive/My Drive/seminar_dl_workspace\")\n",
    "    print(\"switched workspace:\", os.getcwd())\n",
    "\n",
    "from create_visualizations import get_filenames_in_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "def show_svg(filename):\n",
    "    display(SVG(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boilerplate done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [16]\n",
    "learning_rates = [0.01, 0.04, 0.35]\n",
    "momentums = [0.7, 0.725, 0.75, 0.775, 0.8, 0.825, 0.85, 0.875, 0.9, 0.905, 0.91, 0.915, 0.92, 0.925, 0.95, 0.975, 1.0]\n",
    "\n",
    "def get_lr_and_momentum_from_experiment_name(name):\n",
    "    matches = re.search(r\"([0-9]*\\.?[0-9]+)_(\\d+)_([0-9]*\\.?[0-9]+)\\.csv$\", name)\n",
    "    momentum = float(matches.group(1))\n",
    "    batch_size = int(matches.group(2))\n",
    "    lr = float(matches.group(3))\n",
    "    return lr, momentum, batch_size\n",
    "\n",
    "def get_latest_experiment_df(csv_path):\n",
    "    experiment_stats = pd.read_csv(csv_path)\n",
    "    experiment_stats_grouped = experiment_stats.groupby(\"experiment_id\")\n",
    "    latest_training_session = experiment_stats_grouped.get_group(experiment_stats.experiment_id.max())\n",
    "    if len(experiment_stats) < 20:\n",
    "        print(f\"WARNING: file {csv_path} has only {len(experiment_stats)} epochs but should have 20\")\n",
    "    elif len(experiment_stats) > 20 and len(experiment_stats) % 20 == 0:\n",
    "        print(f\"INFO: file {csv_path} has {experiment_stats_grouped.ngroups} training sessions. Using latest training session with {len(latest_training_session)} epochs and experiment_id {latest_training_session.iloc[0]['experiment_id']}\")\n",
    "    return latest_training_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (len(learning_rates), len(momentums))\n",
    "results_test_acc = np.zeros(dims)\n",
    "results_train_acc = np.zeros(dims)\n",
    "results_test_avg_loss = np.zeros(dims)\n",
    "results_train_avg_loss = np.zeros(dims)\n",
    "\n",
    "experiments_stats_filenames = get_filenames_in_dir(\"experiments_stats\", lambda x: \"SGD_with_momentum_\" in x)\n",
    "print(f\"found {len(experiments_stats_filenames)} experiments for SGD_with_momentum_\")\n",
    "for filename in experiments_stats_filenames:\n",
    "    lr, momentum, batch_size = get_lr_and_momentum_from_experiment_name(filename)\n",
    "    if batch_size not in batch_sizes or lr not in learning_rates or momentum not in momentums:\n",
    "        continue\n",
    "    i = learning_rates.index(lr)\n",
    "    k = momentums.index(momentum)\n",
    "    df = get_latest_experiment_df(os.path.join(\"experiments_stats\" , filename))\n",
    "    results_test_acc[i, k] = df[\"test_acc\"].max()\n",
    "    results_train_acc[i, k] = df[\"train_acc\"].max()\n",
    "    results_test_avg_loss[i, k] = df[\"test_avg_loss\"].min()\n",
    "    results_train_avg_loss[i, k] = df[\"train_avg_loss\"].min()\n",
    "\n",
    "max_train_acc = results_train_acc.max()\n",
    "max_test_acc = results_test_acc.max()\n",
    "min_train_loss = results_train_avg_loss.min()\n",
    "min_test_loss = results_test_avg_loss.min()\n",
    "\n",
    "print(f\"max train accuracy: lr={learning_rates[np.where(results_train_acc == max_train_acc)[0][0]]} momentum={momentums[np.where(results_train_acc == max_train_acc)[1][0]]} --> {max_train_acc}\")\n",
    "print(f\"max test accuracy: lr={learning_rates[np.where(results_test_acc == max_test_acc)[0][0]]} momentum={momentums[np.where(results_test_acc == max_test_acc)[1][0]]} --> {max_test_acc}\")\n",
    "print(f\"min train avg loss: lr={learning_rates[np.where(results_train_avg_loss == min_train_loss)[0][0]]} momentum={momentums[np.where(results_train_avg_loss == min_train_loss)[1][0]]} --> {min_train_loss}\")\n",
    "print(f\"min test avg loss:  lr={learning_rates[np.where(results_test_avg_loss == min_test_loss)[0][0]]} momentum={momentums[np.where(results_test_avg_loss == min_test_loss)[1][0]]} --> {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: check results for the more fine grained experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_subplot_bar(ax, data, title, ylabel=\"\", ylim=None, bar_label_y_padding_frac=0.025):\n",
    "    bar_width = 0.25\n",
    "    r1 = [x for x in np.arange(len(data[0, :]))]\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width * 2 for x in r1]\n",
    "    x_labels = list(map(lambda x: str(x), momentums))\n",
    "    ax.bar(r1, data[0, :], width=bar_width, label=\"lr=0.01\")\n",
    "    ax.bar(r2, data[1, :], width=bar_width, color=\"olive\", label=\"lr=0.04\")\n",
    "    ax.bar(r3, data[2, :], width=bar_width, color=\"sienna\", label=\"lr=0.35\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(\"momentum\")\n",
    "    ax.set_xticks([r + bar_width for r in r1])\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.legend()\n",
    "\n",
    "    # set padding for label\n",
    "    bar_label_y_padding = 0\n",
    "    bar_label_y_pos = 0\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "        bar_label_y_padding = (ylim[1] - ylim[0]) * bar_label_y_padding_frac\n",
    "        bar_label_y_pos = ylim[0]\n",
    "    # decide which label should be drawn (only max or min for acc or loss respectively)\n",
    "    lr_001_max = data[0,:].max()\n",
    "    lr_001_min = data[0,:].min()\n",
    "    lr_004_max = data[1,:].max()\n",
    "    lr_004_min = data[1,:].min()\n",
    "    lr_035_max = data[2,:].max()\n",
    "    lr_035_min = data[2,:].min()\n",
    "    for i, v in enumerate(data[0, :]):\n",
    "        if ylabel == \"accuracy\" and v != lr_001_max or ylabel == \"loss\" and v != lr_001_min:\n",
    "            continue\n",
    "        ax.text(i - bar_width / 2, v + bar_label_y_padding, round(v, 3), fontsize=16, color=\"blue\")\n",
    "    for i, v in enumerate(data[1, :]):\n",
    "        if ylabel == \"accuracy\" and v != lr_004_max or ylabel == \"loss\" and v != lr_004_min:\n",
    "            continue\n",
    "        ax.text(i + bar_width / 2, v + bar_label_y_padding, round(v, 3), fontsize=16, color=\"olive\")\n",
    "    for i, v in enumerate(data[2, :]):\n",
    "        if ylabel == \"accuracy\" and v != lr_035_max or ylabel == \"loss\" and v != lr_035_min:\n",
    "            continue\n",
    "        ax.text(i + bar_width / 2, v + bar_label_y_padding, round(v, 3), fontsize=16, color=\"sienna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot avg losses and accuracies for different batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(28, 15), gridspec_kw=dict(hspace=0.35))\n",
    "fig.suptitle(\"SGD with momentum for different momentums and learning rates after 20 epochs (max/min acc/loss for each lr below each graph)\")\n",
    "\n",
    "draw_subplot_bar(axs[0, 0], results_train_acc, \"Train Accuracy for different momentums and learning rates\", ylabel=\"accuracy\", ylim=(0.0, 1.0), bar_label_y_padding_frac=-1.05)\n",
    "draw_subplot_bar(axs[0, 1], results_test_acc, \"Test Accuracy for different momentums and learning rates\", ylabel=\"accuracy\", ylim=(0.0, 1.0))\n",
    "draw_subplot_bar(axs[1, 0], results_train_avg_loss, \"Train avg loss for different momentums and learning rates\", ylabel=\"loss\", ylim=(0.0, 1.0), bar_label_y_padding_frac=-0.225)\n",
    "draw_subplot_bar(axs[1, 1], results_test_avg_loss, \"Test avg loss for different momentums and learning rates\", ylabel=\"loss\", ylim=(0.0, 1.0), bar_label_y_padding_frac=-0.65)\n",
    "\n",
    "plt.savefig(\"visualizations/sgd_with_momentum_batch_sizes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
